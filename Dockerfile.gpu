FROM python:3.12-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    wget \
    curl \
    ca-certificates \
    gnupg \
    lsb-release \
    software-properties-common \
    libgdk-pixbuf-xlib-2.0-0 \
    equivs \
    && rm -rf /var/lib/apt/lists/*

# Create dummy package for obsolete libgdk-pixbuf2.0-0
RUN echo 'Package: libgdk-pixbuf2.0-0\nVersion: 2.42.10-1ubuntu1\nArchitecture: all\nDescription: Dummy package for libgdk-pixbuf2.0-0\nProvides: libgdk-pixbuf2.0-0' > /tmp/libgdk-pixbuf2.0-0.control && \
    cd /tmp && equivs-build libgdk-pixbuf2.0-0.control && \
    dpkg -i libgdk-pixbuf2.0-0_2.42.10-1ubuntu1_all.deb && \
    rm -f /tmp/libgdk-pixbuf2.0-0*

# Add NVIDIA repository and install CUDA
RUN wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb && \
    dpkg -i cuda-keyring_1.0-1_all.deb && \
    apt-get update && \
    apt-get install -y cuda-toolkit-12-1 cuda-runtime-12-1 && \
    rm cuda-keyring_1.0-1_all.deb && \
    rm -rf /var/lib/apt/lists/*

# Install NVIDIA Container Toolkit
RUN distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
    curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && \
    curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    tee /etc/apt/sources.list.d/nvidia-container-toolkit.list && \
    apt-get update && \
    apt-get install -y nvidia-container-toolkit nvidia-container-runtime && \
    rm -rf /var/lib/apt/lists/*

# Set environment variables for GPU support
ENV TARGET_ARCH=aarch64
ENV TARGET_PLATFORM=linux
ENV GPT4ALL_MODEL_DIR=/app/models
ENV PYTHONPATH=/usr/local/lib/python3.12/site-packages
ENV CUDA_VISIBLE_DEVICES=0
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
ENV NVIDIA_RUNTIME_VERSION=12.1
ENV CUDA_VERSION=12.1
ENV PATH=/usr/local/cuda-12.1/bin:$PATH
ENV LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH

# Copy requirements and install Python dependencies
COPY requirements.gpu.txt requirements.txt
RUN pip3 install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create models directory and download Linux models during build
RUN mkdir -p /app/models && \
    cd /app/models && \
    wget -O mistral-7b-instruct-v0.1.Q4_0.gguf https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf && \
    wget -O mistral-7b-openorca.gguf2.Q4_0.gguf https://gpt4all.io/models/gguf/mistral-7b-openorca.gguf2.Q4_0.gguf && \
    echo "Models downloaded successfully"

# Create startup script for Cloud Run
RUN echo '#!/bin/bash\n\
echo "Starting Truify with GPU support..."\n\
echo "CUDA Version: $CUDA_VERSION"\n\
echo "NVIDIA Runtime Version: $NVIDIA_RUNTIME_VERSION"\n\
echo "GPU Devices: $CUDA_VISIBLE_DEVICES"\n\
echo "CUDA Path: $PATH"\n\
echo "LD Library Path: $LD_LIBRARY_PATH"\n\
nvidia-smi || echo "nvidia-smi not available (normal for Cloud Run)"\n\
nvcc --version || echo "nvcc not available (normal for Cloud Run)"\n\
exec streamlit run code/main.py --server.port=8501 --server.address=0.0.0.0\n\
' > /app/start.sh && chmod +x /app/start.sh

# Expose port
EXPOSE 8501

# Start Streamlit
CMD ["/app/start.sh"]
